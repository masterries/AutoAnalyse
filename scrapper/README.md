# AutoScout24 Luxembourg Scraper

Ein robuster, tÃ¤glich laufender Web-Scraper fÃ¼r AutoScout24.lu mit PreisÃ¤nderungs-Tracking und modernem Frontend.

## ğŸš€ Features

- **Intelligentes Scraping** - Automatische Seitenerkennung mit adaptiver VerzÃ¶gerung
- **Multi-Model Support** - Mehrere Fahrzeugmodelle parallel scrapen
- **SQLite-Datenbank** - Robuste Datenspeicherung mit Preishistorie
- **PreisÃ¤nderungs-Tracking** - Automatische Erkennung von PreisÃ¤nderungen
- **Log-Management** - Automatische Komprimierung und Bereinigung
- **Frontend Dashboard** - Moderne WeboberflÃ¤che fÃ¼r Datenanalyse
- **GitHub Actions** - TÃ¤glich automatisches Scraping um 4:00 AM UTC

## ğŸ“ Struktur

```
scrapper/
â”œâ”€â”€ autoscout_luxembourg_scraper.py  # Haupt-Scraper
â”œâ”€â”€ database.py                      # SQLite-Datenbankmanager
â”œâ”€â”€ log_manager.py                   # Log-Verwaltung
â”œâ”€â”€ requirements.txt                 # Python-Dependencies
â”œâ”€â”€ vehicle_models.csv               # Multi-Model-Konfiguration
â”œâ”€â”€ data/                           # Ausgabedaten
â”‚   â”œâ”€â”€ autoscout_data.db           # SQLite-Datenbank
â”‚   â”œâ”€â”€ logs/                       # Log-Dateien
â”‚   â””â”€â”€ *.csv                       # CSV-Exporte
â””â”€â”€ frontend/                       # Dashboard
    â”œâ”€â”€ index.html                  # Haupt-Dashboard
    â”œâ”€â”€ style.css                   # Styling
    â””â”€â”€ script.js                   # Interaktive Features
```

## ğŸ› ï¸ Installation

```bash
# Dependencies installieren
pip install -r requirements.txt

# Einzelnes Modell scrapen
python3 autoscout_luxembourg_scraper.py --make bmw --model 120 --scrape-all

# Multi-Model Scraping
python3 autoscout_luxembourg_scraper.py --multi-model vehicle_models.csv --scrape-all
```

## ğŸ“Š Verwendung

### Grundlegendes Scraping
```bash
# BMW 120 scrapen (automatische Seitenerkennung)
python3 autoscout_luxembourg_scraper.py --make bmw --model 120 --scrape-all

# Mit spezifischer Seitenzahl
python3 autoscout_luxembourg_scraper.py --make mercedes-benz --model a-200 --pages 5
```

### Multi-Model Scraping
```bash
# Alle Modelle aus vehicle_models.csv scrapen
python3 autoscout_luxembourg_scraper.py --multi-model vehicle_models.csv --scrape-all --delay 3
```

### Statistiken anzeigen
```bash
# Alle Fahrzeugmodelle auflisten
python3 autoscout_luxembourg_scraper.py --list-models

# Statistiken fÃ¼r ein Modell
python3 autoscout_luxembourg_scraper.py --make bmw --model 120 --stats
```

### Log-Management
```bash
# Log-Statistiken anzeigen
python3 log_manager.py --stats

# Manuelle Log-Wartung
python3 log_manager.py --maintenance
```

## ğŸŒ Frontend Dashboard

Ã–ffne `frontend/index.html` im Browser fÃ¼r:
- **Preisanalyse** - Durchschnittspreise, Min/Max, Trends
- **Filterung** - Nach Marke, Modell, Kraftstoff, etc.
- **Visualisierung** - Charts und Diagramme
- **Export** - CSV-Download der gefilterten Daten

## âš™ï¸ Konfiguration

### vehicle_models.csv
```csv
make,model
mercedes-benz,a-180
mercedes-benz,a-200
mercedes-benz,c-200
bmw,120
bmw,320
```

### Wichtige Parameter
- `--scrape-all`: Automatische Seitenerkennung (empfohlen)
- `--delay X`: VerzÃ¶gerung zwischen Requests (Standard: 2s)
- `--csv-mode`: CSV-Dateien statt SQLite verwenden
- `--no-auto-stop`: Weitermachen auch bei leeren Seiten

## ğŸ¤– GitHub Actions

Der Scraper lÃ¤uft tÃ¤glich automatisch:
- **Zeit**: 4:00 AM UTC
- **Befehl**: `python3 autoscout_luxembourg_scraper.py --multi-model vehicle_models.csv --scrape-all`
- **Commit**: Automatisch bei DatenÃ¤nderungen

## ğŸ“ˆ Datenbank-Schema

- **listings**: Aktuelle Fahrzeug-Listings
- **price_history**: PreisÃ¤nderungen Ã¼ber Zeit
- **metadata**: Scraping-Metadaten und Statistiken

## ğŸ”§ Log-Management

- **Automatisch**: Logs Ã¤lter als 7 Tage werden komprimiert
- **Cleanup**: Komprimierte Logs Ã¤lter als 30 Tage werden gelÃ¶scht
- **Manuell**: `python3 log_manager.py --maintenance`

## ğŸš— UnterstÃ¼tzte Fahrzeugdaten

- Preis, Kilometerstand, Kraftstoffart
- Erstzulassung, Leistung, Getriebe
- VerkÃ¤ufertyp, Standort, URL
- Automatisches PreisÃ¤nderungs-Tracking

## âš¡ Performance

- **Adaptive VerzÃ¶gerung** - Passt sich an Serverantwortzeit an
- **Duplikat-Erkennung** - Verhindert doppelte Listings
- **Intelligenter Stop** - Stoppt bei leeren Seiten
- **Effizienz**: ~1-2 Listings/Sekunde

## ğŸ“‹ Requirements

- Python 3.8+
- requests, beautifulsoup4, pandas
- SQLite3 (Standard in Python)

FÃ¼r vollstÃ¤ndige Liste siehe `requirements.txt`.
